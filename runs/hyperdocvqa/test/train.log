08/25/2021 13:41:12 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
08/25/2021 13:41:18 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='../../runs/hyperdocvqa/test/models', config_name='', data_dir='/mlcv/Databases/DocVQA_2020-21/task_1/train', device=device(type='cuda', index=0), do_eval=True, do_lower_case=True, do_predict=False, do_train=True, doc_stride=128, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='/mlcv/Databases/DocVQA_2020-21/model_layoutlm/layoutlm_base_uncased/', model_type='layoutlm', n_gpu=1, no_cuda=False, num_train_epochs=2.0, output_dir='../../runs/hyperdocvqa/test', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=2, save_steps=500, seed=42, server_ip='', server_port='', skip_match_answers=True, tokenizer_name='', train_json='./train.json', val_json='./val.json', warmup_steps=0, weight_decay=0.0)
08/25/2021 13:41:21 - INFO - __main__ -   Loading train json from ./train.json
08/25/2021 13:41:21 - INFO - __main__ -   Loading features from cached file /mlcv/Databases/DocVQA_2020-21/task_1/train/cached_train_layoutlm_base_uncased_128
08/25/2021 13:41:56 - INFO - __main__ -   ***** Running training *****
08/25/2021 13:41:56 - INFO - __main__ -     Num examples = 105507
08/25/2021 13:41:56 - INFO - __main__ -     Num Epochs = 2
08/25/2021 13:41:56 - INFO - __main__ -     Instantaneous batch size per GPU = 2
08/25/2021 13:41:56 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 2
08/25/2021 13:41:56 - INFO - __main__ -     Gradient Accumulation steps = 1
08/25/2021 13:41:56 - INFO - __main__ -     Total optimization steps = 105508
